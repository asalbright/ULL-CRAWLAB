2pm EDT on 03/30/22

# Presentation Notes

## General Questions:
* Do the Boston dynamics robots use RL?
* Are there any other systems that could use this concurrent learning/design method?

## Committee Questions:
* Did you use a nonlinear spring?
* Slide 25: It looks like the efficient agent doesn’t stutter jump?
* Slide 28: It looks like Efficient gets more air time?
* Slide 55: Why would you use different rewards functions here for the same goal?

## Formatting:
* Slide 2: I wouldn’t abbreviate “parameters.” Just a suggestion.
* Slide 40: The action definition is change from nominal.
* Slide 46: Borad!
* Slide 52: target becavior policy

## Tips:
* Slide 12: 11 minutes to get to discussion of current research
* Slide 50: You spend a lot of time here on update rates without new illustrations. (edited) 